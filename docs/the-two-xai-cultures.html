<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 The Two XAI Cultures | Adversarial Model Analysis</title>
  <meta name="description" content="Red Team Notes" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 The Two XAI Cultures | Adversarial Model Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Red Team Notes" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 The Two XAI Cultures | Adversarial Model Analysis" />
  
  <meta name="twitter:description" content="Red Team Notes" />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="Przemysław Biecek" />


<meta name="date" content="2023-12-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="model-evaluation-levels.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>Adversarial Model Analysis</h3> RedTeam Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html"><i class="fa fa-check"></i><b>1</b> The Two XAI Cultures</a>
<ul>
<li class="chapter" data-level="1.1" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#user-oriented-explanations"><i class="fa fa-check"></i><b>1.1.1</b> User Oriented Explanations</a></li>
<li class="chapter" data-level="1.1.2" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#the-developer-oriented-explanations"><i class="fa fa-check"></i><b>1.1.2</b> The Developer Oriented Explanations</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#challenges"><i class="fa fa-check"></i><b>1.2</b> Challenges</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#achilles-heels"><i class="fa fa-check"></i><b>1.2.1</b> Achilles’ heels</a></li>
<li class="chapter" data-level="1.2.2" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#rashomon-perspectives"><i class="fa fa-check"></i><b>1.2.2</b> Rashomon perspectives</a></li>
<li class="chapter" data-level="1.2.3" data-path="the-two-xai-cultures.html"><a href="the-two-xai-cultures.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>1.2.3</b> Champion Challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="model-evaluation-levels.html"><a href="model-evaluation-levels.html"><i class="fa fa-check"></i><b>2</b> Model Evaluation Levels</a></li>
<li class="chapter" data-level="3" data-path="mitre-attck.html"><a href="mitre-attck.html"><i class="fa fa-check"></i><b>3</b> MITRE ATT&amp;CK</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mitre-attck.html"><a href="mitre-attck.html#tactics"><i class="fa fa-check"></i><b>3.1</b> Tactics</a></li>
<li class="chapter" data-level="3.2" data-path="mitre-attck.html"><a href="mitre-attck.html#techniques"><i class="fa fa-check"></i><b>3.2</b> Techniques</a></li>
<li class="chapter" data-level="3.3" data-path="mitre-attck.html"><a href="mitre-attck.html#procedures"><i class="fa fa-check"></i><b>3.3</b> Procedures</a></li>
<li class="chapter" data-level="3.4" data-path="mitre-attck.html"><a href="mitre-attck.html#attck-for-ai-systems"><i class="fa fa-check"></i><b>3.4</b> ATT&amp;CK for AI systems</a></li>
<li class="chapter" data-level="3.5" data-path="mitre-attck.html"><a href="mitre-attck.html#pros-and-cons"><i class="fa fa-check"></i><b>3.5</b> Pros and cons</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html"><i class="fa fa-check"></i><b>4</b> Open Worldwide Application Security Project (OWASP)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml012023-input-manipulation-attack"><i class="fa fa-check"></i><b>4.1</b> ML01:2023 Input Manipulation Attack</a></li>
<li class="chapter" data-level="4.2" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml022023-data-poisoning-attack"><i class="fa fa-check"></i><b>4.2</b> ML02:2023 Data Poisoning Attack</a></li>
<li class="chapter" data-level="4.3" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml032023-model-inversion-attack"><i class="fa fa-check"></i><b>4.3</b> ML03:2023 Model Inversion Attack</a></li>
<li class="chapter" data-level="4.4" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml042023-membership-inference-attack"><i class="fa fa-check"></i><b>4.4</b> ML04:2023 Membership Inference Attack</a></li>
<li class="chapter" data-level="4.5" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml052023-model-stealing"><i class="fa fa-check"></i><b>4.5</b> ML05:2023 Model Stealing</a></li>
<li class="chapter" data-level="4.6" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml062023-ai-supply-chain-attacks"><i class="fa fa-check"></i><b>4.6</b> ML06:2023 AI Supply Chain Attacks</a></li>
<li class="chapter" data-level="4.7" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml072023-troyan-horse-attack"><i class="fa fa-check"></i><b>4.7</b> ML07:2023 Troyan Horse Attack</a></li>
<li class="chapter" data-level="4.8" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml082023-model-skewing"><i class="fa fa-check"></i><b>4.8</b> ML08:2023 Model Skewing</a></li>
<li class="chapter" data-level="4.9" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml092023-output-integrity-attack"><i class="fa fa-check"></i><b>4.9</b> ML09:2023 Output Integrity Attack</a></li>
<li class="chapter" data-level="4.10" data-path="open-worldwide-application-security-project-owasp.html"><a href="open-worldwide-application-security-project-owasp.html#ml102023-model-poisoning"><i class="fa fa-check"></i><b>4.10</b> ML10:2023 Model Poisoning</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="nist-ai-risk-management-framework-ai-rmf.html"><a href="nist-ai-risk-management-framework-ai-rmf.html"><i class="fa fa-check"></i><b>5</b> NIST AI Risk Management Framework (AI RMF)</a></li>
<li class="chapter" data-level="6" data-path="adversarial-robustness-toolbox-art.html"><a href="adversarial-robustness-toolbox-art.html"><i class="fa fa-check"></i><b>6</b> Adversarial Robustness Toolbox (ART)</a></li>
<li class="chapter" data-level="7" data-path="dependable-and-explainable-learning-deel.html"><a href="dependable-and-explainable-learning-deel.html"><i class="fa fa-check"></i><b>7</b> DEpendable and Explainable Learning (DEEL)</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Adversarial Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-two-xai-cultures" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> The Two XAI Cultures<a href="the-two-xai-cultures.html#the-two-xai-cultures" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In 2001, Leo Breiman published a phenomenal paper “The Two Cultures” <span class="citation"><a href="#ref-breiman2001statistical">[1]</a></span>, in which he diagnosed the growing gap between the mainstream trends in academic research conducted by statisticians against new challenges, such as the curse of dimensionality, the construction of effective predictive algorithms.
His paper is so well constructed that its narrative structure can be applied to diagnose problems in many research areas standing on the edge of an identity crisis.</p>
<p>In this chapter, I argue that the field of explainable artificial intelligence (XAI) is also facing such a crisis, and two cultures of researchers are evident in this area as well. Moreover, without a better understanding of the different goals facing these cultures, no further progress is possible.</p>
<p>In the second part of this chapter, three key challenges facing one culture are presented and illustrated using a real dataset as an example.</p>
<div id="introduction-1" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction<a href="the-two-xai-cultures.html#introduction-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Machine learning starts with models.
Think of a model as a function <span class="math inline">\(f:\mathcal R^d \rightarrow \mathcal R\)</span> that calculates a numerical score based on <span class="math inline">\(d\)</span>-dimensional input.
In machine learning, these functions are often constructed based on training data and their internal operations are complex, often described by thousands, millions or even billions of parameters. Direct parameter-by-parameter analysis of the model is often not feasible, but reasoning about the model’s behavior is desired. At least two goals of analyzing the model can be identified.</p>
<p><em>Communication</em> of the key premises behind model predictions. The premises should be in line with user expectations and knowledge.</p>
<p><em>Discovering</em> situations in which the model does not work as expected by an operator. In such a situation, the model’s predictions may be wrong or the operator’s expectations may be wrong.</p>
<p>There are two different approaches toward these goals:</p>
<div id="user-oriented-explanations" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> User Oriented Explanations<a href="the-two-xai-cultures.html#user-oriented-explanations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to think about explanations is from the perspective of a citizen who receives a decision that he/she doesn’t understand, or disagrees with, or is curious about, and asks ‘where did this decision come from?’ Whether it involves credit, or access to medical services, or restaurant recommendations is secondary. The important thing is that the person asking ‘Why’ is the user of the AI system.</p>
<p>This perspective places the emphasis on the model’s decision received by a particular individual and assumes that explainability will help him accept or challenge that decision.</p>
<div class="float">
<img src="images/two-culture-users.png" alt="User Oriented Explanations" />
<div class="figcaption">User Oriented Explanations</div>
</div>
<p>Analysis of a model in this culture is oriented toward user rights (e.g. mythical ,,right to explain’’). Discussion of the need for and desirability of explanations revolves around such concepts as trust, right to explanation, causality, fair and ethical decision-making. informativeness. A paper that has resonated and illustrates well the perspective of this culture is <span class="citation"><a href="#ref-Lipton2018">[2]</a></span>.</p>
<p><em>When</em>: this perspective is most prevalent after model deployment.</p>
<p><em>Validation</em>: user studies (although there are now more papers saying that a user study is needed than papers that take a professional approach to the topic of user study).</p>
<p><em>Estimated culture population</em>: majority of those publishing in the XAI area.</p>
</div>
<div id="the-developer-oriented-explanations" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> The Developer Oriented Explanations<a href="the-two-xai-cultures.html#the-developer-oriented-explanations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another perspective on thinking about explanations is through eyes an engineer building or testing a model, who wants the model to work in every, or almost every, case. Explanations can help diagnose and perhaps fix errors in model performance.</p>
<p>This perspective emphasizes the model that should work well for all sorts of data.</p>
<div class="float">
<img src="images/two-culture-developers.png" alt="Developer Oriented Explanations" />
<div class="figcaption">Developer Oriented Explanations</div>
</div>
<p>Analysis of a model in this culture is oriented toward new ideas on how to improve the model.
Typical questions asked by this culture are if explanations are fidel to the model, give global perspective, can be used to debug models, can be used to improve models. A very popular paper that gives this perspective is <span class="citation"><a href="#ref-ribeiro2016why">[3]</a></span>.</p>
<p><em>When</em>: this perspective is most prevalent before model deployment. Although it can also be present after deployment (e.g., monitoring model performance, port-mortem analysis).</p>
<p><em>Validation</em>: Effectiveness in finding model weaknesses, effectiveness in generating new and better models.</p>
<p><em>Estimated culture population</em>: most people using XAI in a business setting</p>
</div>
</div>
<div id="challenges" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Challenges<a href="the-two-xai-cultures.html#challenges" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section I will argue that the focus in the user oriented explanations has:</p>
<ul>
<li>Led to irrelevant theory and questionable scientific conclusions (since in mose cases the target user population is not specified)</li>
<li>Kept ML researchers from using more suitable performance measures (since measuring trust in very shady concept)</li>
<li>Prevented ML researchers from working on exciting new problems (since it is hard to do progress without good validation scheme)</li>
</ul>
<p>The developer-focused perspective offers interesting new challenges just waiting to be solved. I offer three example problems below. In part they intersect with Breiman’s proposals (n.p. Rashomon perspective), in part they are specific to XAI techniques.</p>
<div id="achilles-heels" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Achilles’ heels<a href="the-two-xai-cultures.html#achilles-heels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Identifying potential weaknesses of the model, finding its Achilles’ heel.</p>
<p>TODO: refer to the FIFA case and
<a href="https://journal.r-project.org/archive/2019/RJ-2019-036/index.html" class="uri">https://journal.r-project.org/archive/2019/RJ-2019-036/index.html</a></p>
</div>
<div id="rashomon-perspectives" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Rashomon perspectives<a href="the-two-xai-cultures.html#rashomon-perspectives" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Understanding the root cause of identified problems - Rashomon perspectives.</p>
<p>TODO: refer to <a href="https://arxiv.org/abs/2302.13356" class="uri">https://arxiv.org/abs/2302.13356</a></p>
</div>
<div id="champion-challenger-analysis" class="section level3 hasAnchor" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Champion Challenger analysis<a href="the-two-xai-cultures.html#champion-challenger-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Apply mitigation strategies and see if they worked and led to better model behavior - Champion Challenger analysis.</p>
<p>TODO:
refer / extend analysis of funnel plot from <a href="https://modeloriented.github.io/DALEXtra/reference/funnel_measure.html" class="uri">https://modeloriented.github.io/DALEXtra/reference/funnel_measure.html</a></p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-breiman2001statistical" class="csl-entry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">L. Breiman, <span>“Statistical modeling: The two cultures,”</span> <em>Statistical Science</em>, vol. 16, no. 3, pp. 199–231, 2001, doi: <a href="https://doi.org/10.1214/ss/1009213726">10.1214/ss/1009213726</a>.</div>
</div>
<div id="ref-Lipton2018" class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Z. C. Lipton, <span>“<span class="nocase">The Mythos of Model Interpretability</span>,”</span> <em>Queue</em>, vol. 16, no. 3, pp. 31–57, 2018, doi: <a href="https://doi.org/10.1145/3236386.3241340">10.1145/3236386.3241340</a>.</div>
</div>
<div id="ref-ribeiro2016why" class="csl-entry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">M. T. Ribeiro, S. Singh, and C. Guestrin, <span>“<span class="nocase">”Why Should I Trust You?”: Explaining the Predictions of Any Classifier</span>,”</span> in <em>ACM SIGKDD conference on knowledge discovery and data mining</em>, 2016, pp. 1135–1144. doi: <a href="https://doi.org/10.1145/2939672.2939778">10.1145/2939672.2939778</a>.</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-evaluation-levels.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pbiecek/ama/edit/master/01-two-cultures.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
